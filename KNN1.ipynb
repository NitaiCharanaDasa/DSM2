{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "274f6b4b-26ba-4a4c-b8b9-43704d41e21b",
   "metadata": {},
   "source": [
    "# KNN 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13870cb-8bdd-41e2-8bbc-e6d0e163fb52",
   "metadata": {},
   "source": [
    "Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ec38f-4399-4b7c-8548-4ce0028084be",
   "metadata": {},
   "source": [
    "1. **KNN Algorithm:**\n",
    "   - KNN (K-Nearest Neighbors) is a supervised machine learning algorithm used for both classification and regression tasks.\n",
    "   - It makes predictions based on the majority class (for classification) or the average of K-nearest neighbors' values (for regression).\n",
    "2. **Choosing the Value of K in KNN:**\n",
    "   - The value of K is crucial and can impact the model's performance.\n",
    "   - Choosing a small K may lead to noise sensitivity, while a large K may smooth out patterns.\n",
    "   - Typically, K is chosen through cross-validation, considering the trade-off between bias and variance.\n",
    "3. **KNN Classifier vs. KNN Regressor:**\n",
    "   - KNN Classifier predicts the class label based on majority voting.\n",
    "   - KNN Regressor predicts a continuous value based on the average of K-nearest neighbors' values.\n",
    "4. **Measuring Performance of KNN:**\n",
    "   - Common metrics for classification: accuracy, precision, recall, F1-score.\n",
    "   - For regression: mean squared error, mean absolute error, R-squared.\n",
    "5. **Curse of Dimensionality in KNN:**\n",
    "   - As the number of features increases, the distance between points becomes more uniform, making it harder to identify close neighbors.\n",
    "   - This can lead to reduced effectiveness and increased computational complexity.\n",
    "6. **Handling Missing Values in KNN:**\n",
    "   - Impute missing values before applying KNN, as it relies on distances between data points.\n",
    "   - Techniques include mean imputation, k-NN imputation, or other advanced imputation methods.\n",
    "7. **Performance of KNN Classifier vs. Regressor:**\n",
    "   - KNN Classifier is suitable for categorical problems with distinct classes.\n",
    "   - KNN Regressor is appropriate for problems with continuous target variables.\n",
    "8. **Strengths and Weaknesses of KNN:**\n",
    "   - *Strengths:* Simple to understand, no training phase, effective for small datasets.\n",
    "   - *Weaknesses:* Sensitive to outliers, computationally expensive for large datasets, requires appropriate distance metric selection.\n",
    "9. **Euclidean Distance vs. Manhattan Distance in KNN:**\n",
    "   - *Euclidean Distance:* Measures the straight-line distance between two points.\n",
    "   - *Manhattan Distance:* Sum of the absolute differences between corresponding coordinates.\n",
    "   - The choice depends on the nature of the data and the problem at hand.\n",
    "10. **Role of Feature Scaling in KNN:**\n",
    "    - Feature scaling is crucial as KNN relies on distance metrics.\n",
    "    - Without scaling, features with larger scales may dominate the distance calculations.\n",
    "    - Common techniques include Min-Max scaling or standardization to ensure equal contribution from all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d4aa0c-6afc-4ec9-9be5-e365fc963df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
